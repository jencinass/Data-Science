# -*- coding: utf-8 -*-
"""Differentiated Thyroid Cancer Recurrence.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nlb3KPzbjMq_vyUd0NAuuq5_ACzGJu_y
"""

# prompt: importa pandas y crea un read csv df = /content/sample_data/Thyroid_Diff.csv

import pandas as pd
df = pd.read_csv('/content/sample_data/Thyroid_Diff.csv')
df.head()

from sklearn.preprocessing import StandardScaler, LabelEncoder

# Preprocesamiento de datos

# Codificación de variables categóricas
label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# Escalado de características
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df)

# Mostrando las primeras filas del dataframe transformado para verificar los cambios
pd.DataFrame(scaled_features, columns=df.columns).head()

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Método del codo para determinar el número óptimo de clusters
inertia = []
k_range = range(1, 11)  # Probaremos con 1 a 10 clusters

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

# Graficando el método del codo
plt.figure(figsize=(10, 6))
plt.plot(k_range, inertia, marker='o')
plt.title('Método del Codo para Determinar K Óptimo')
plt.xlabel('Número de Clusters')
plt.ylabel('Inercia')
plt.xticks(k_range)
plt.show()

# Aplicando K-means con 3 clusters
k = 3
kmeans = KMeans(n_clusters=k, random_state=0)
kmeans.fit(scaled_features)

# Añadiendo las etiquetas de los clusters al dataframe original
df['Cluster'] = kmeans.labels_

# Mostrando las primeras filas del dataframe con las etiquetas de cluster añadidas
df.head()

import seaborn as sns

# Analizando los clusters para entender sus características
cluster_summary = df.groupby('Cluster').mean()

# Visualización de los clusters
# Debido a la alta dimensionalidad de los datos, usaremos un par de características para visualizar
# Elegiremos dos características numéricas para una visualización 2D
# Aquí, elegiremos 'Age' y otra característica numérica para la visualización
feature_for_visualization = 'Thyroid Function'  # Ejemplo, puede ser cualquier otra característica numérica

plt.figure(figsize=(12, 6))
sns.scatterplot(data=df, x='Age', y=feature_for_visualization, hue='Cluster', palette='viridis')
plt.title('Visualización de Clusters con Edad y Función Tiroidea')
plt.show()

cluster_summary

from sklearn.decomposition import PCA

# Reducción de la dimensionalidad con PCA
pca = PCA(n_components=2)  # Reduciendo a 2 componentes para visualización 2D
pca_result = pca.fit_transform(scaled_features)

# Creando un DataFrame para la visualización
df_pca = pd.DataFrame(data=pca_result, columns=['PCA1', 'PCA2'])
df_pca['Cluster'] = df['Cluster']

# Visualización de los clusters después de la reducción de PCA
plt.figure(figsize=(12, 6))
sns.scatterplot(data=df_pca, x='PCA1', y='PCA2', hue='Cluster', palette='viridis')
plt.title('Visualización de Clusters con PCA')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.show()

# Explorando más a fondo cada cluster

# Crearemos tres dataframes, uno para cada cluster, para facilitar el análisis de las características específicas
df_cluster_0 = df[df['Cluster'] == 0]
df_cluster_1 = df[df['Cluster'] == 1]
df_cluster_2 = df[df['Cluster'] == 2]

# Análisis descriptivo de cada cluster
desc_cluster_0 = df_cluster_0.describe()
desc_cluster_1 = df_cluster_1.describe()
desc_cluster_2 = df_cluster_2.describe()

(desc_cluster_0, desc_cluster_1, desc_cluster_2)

import numpy as np

# Ajustando el nuevo registro de prueba para que tenga el número correcto de características
# Añadiremos un valor para la característica faltante
new_data_adjusted = np.array([[45,  # Age
                               1,   # Gender (supongamos que 1 representa 'F')
                               1,   # Smoking Hx (supongamos que 1 representa 'Sí')
                               0,   # Smoking Hx Radiothreapy (supongamos que 0 representa 'No')
                               2,   # Thyroid Function
                               3,   # Physical Examination
                               3,   # Adenopathy
                               2,   # Pathology
                               1,   # Focality
                               2,   # Risk
                               3,   # T
                               0,   # N
                               0,   # M
                               1,   # Stage
                               2,   # Response
                               0,   # Recurred
                               0]]) # Añadimos una característica adicional para completar 17 características

# Escalando los nuevos datos
new_data_scaled_adjusted = scaler.transform(new_data_adjusted)

# Usando el modelo K-means para asignar el nuevo registro a un cluster
predicted_cluster_adjusted = kmeans.predict(new_data_scaled_adjusted)
predicted_cluster_adjusted[0]

predicted_cluster_adjusted

