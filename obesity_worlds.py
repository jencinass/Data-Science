# -*- coding: utf-8 -*-
"""Obesity_worlds.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dRz3B3r2WkzgjCarlZoaZbylljNDkmQn
"""

# prompt: read csv "/content/sample_data/obesity new.csv" df.head

import pandas as pd
df = pd.read_csv('/content/sample_data/obesity new.csv')
df.head()

df.info()

# prompt: shape

df.shape

df.describe()

# Revisar los tipos de datos y valores únicos de las columnas con tipo 'object'
object_columns = df.select_dtypes(include=['object']).columns
unique_values_in_object_columns = {col: df[col].unique() for col in object_columns}

# Contar los valores nulos en cada columna
null_values_count = df.isnull().sum()

unique_values_in_object_columns, null_values_count

import numpy as np

# Función para convertir valores a numéricos y manejar los no numéricos
def to_numeric(column):
    """
    Convert a column to numeric type. Non-numeric values are replaced with NaN.
    """
    return pd.to_numeric(column, errors='coerce')

# Aplicar la función a todas las columnas que deben ser numéricas
for col in object_columns:
    df[col] = to_numeric(df[col])

# Verificar los cambios y contar los valores NaN después de la conversión
data_types_after_conversion = df.dtypes
nan_values_after_conversion = df.isna().sum()

data_types_after_conversion, nan_values_after_conversion

# Imputar los valores NaN con la mediana para cada columna
for col in ["Age", "FCVC", "NCP", "CH2O", "FAF", "TUE"]:
    median_value = df[col].median()
    df[col].fillna(median_value, inplace=True)

# Verificar si aún hay valores NaN después de la imputación
nan_values_after_imputation = df.isna().sum()
nan_values_after_imputation

import matplotlib.pyplot as plt
import seaborn as sns

# Configuración de los gráficos
sns.set(style="whitegrid")

# Lista de algunas variables para visualización
variables_to_visualize = ["Age", "Gender", "family_history_with_overweight", "FAVC", "FCVC", "NCP", "CAEC", "SMOKE", "CH2O", "SCC", "FAF", "TUE", "CALC", "NObeyesdad"]

# Crear una figura y un conjunto de subplots
fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 20))

# Aplanar la matriz de ejes
axes = axes.flatten()

# Bucle para crear un gráfico para cada variable
for i, col in enumerate(variables_to_visualize):
    if df[col].dtype == 'int64' or df[col].dtype == 'float64':
        # Gráficos para variables continuas o discretas
        sns.histplot(df[col], ax=axes[i], kde=True, bins=30)
        axes[i].set_title(col, fontsize=14)
        axes[i].set_ylabel('Count')
    else:
        # Gráficos para variables categóricas
        sns.countplot(x=col, data=df, ax=axes[i])
        axes[i].set_title(col, fontsize=14)
        axes[i].set_ylabel('Count')

# Ajustar el layout y mostrar los gráficos
plt.tight_layout()
plt.show()

# Calcular la matriz de correlación
correlation_matrix = df.corr()

# Configurar el tamaño de la figura
plt.figure(figsize=(15, 10))

# Crear un mapa de calor para visualizar la matriz de correlación
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)

# Título y mostrar el gráfico
plt.title("Matriz de Correlación", fontsize=18)
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Definir las características y la variable objetivo
X = df.drop('NObeyesdad', axis=1)
y = df['NObeyesdad']

# Dividir el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Crear un modelo de Random Forest para evaluar la importancia de las características
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Evaluar la importancia de las características
feature_importances = pd.DataFrame(rf.feature_importances_, index=X_train.columns, columns=['importance']).sort_values('importance', ascending=False)

# Predecir con el conjunto de prueba
y_pred = rf.predict(X_test)

# Calcular la precisión y mostrar el reporte de clasificación
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

feature_importances, accuracy, classification_rep, confusion_mat

# Visualización mejorada de la importancia de las características
plt.figure(figsize=(10, 6))
sns.barplot(x=feature_importances.importance, y=feature_importances.index)
plt.title('Importancia de las Características en el Modelo Random Forest')
plt.xlabel('Importancia')
plt.ylabel('Características')
plt.show()

# Visualización de la precisión
accuracy_str = f"Exactitud del Modelo: {accuracy*100:.2f}%"
print(accuracy_str)

# Formatear y visualizar el reporte de clasificación
print("\nReporte de Clasificación:\n")
print(classification_rep)

# Visualización de la matriz de confusión
plt.figure(figsize=(6, 6))
sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues", square=True)
plt.title('Matriz de Confusión')
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.show()

# Crear un nuevo objeto para hacer una predicción
# Usaremos las medias de las variables para crear un objeto representativo

new_object = X.mean().to_frame().T
new_object_prediction = rf.predict(new_object)
predicted_class = "Obeso" if new_object_prediction[0] == 1 else "No Obeso"

new_object, predicted_class

